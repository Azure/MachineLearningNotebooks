{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This notebook demonstrates how to run a batch scoring job. The [Inception-V3 model](https://arxiv.org/abs/1512.00567) and unlabeled images from the [ImageNet](http://image-net.org/) dataset are used. This example registers a pretrained inception model in the model registry, then it uses the model to do batch scoring on images in a blob container."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prerequisites\nFollow the steps in the [00. Installation and Configuration](./00.configuration.ipynb) Notebook to:\n1. Install the Azure Machine Learning SDK and libraries\n2. Register your subscription\n3. Set up an Azure Machine Learning workspace\n4. Create compute resources for training experiments\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## What is this first step?\n***What does the following code do?***"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom azureml.core import Workspace, Run, Experiment\n\nws = Workspace.from_config()\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')\n\n# Also create a Project and attach to Workspace\nscripts_folder = \"scripts\"\n\nif not os.path.isdir(scripts_folder):\n    os.mkdir(scripts_folder)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UserErrorException",
          "evalue": "We could not find config.json in: /home/nbuser/library or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d11d55896fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m print('Workspace name: ' + ws.name, \n\u001b[1;32m      6\u001b[0m       \u001b[0;34m'Azure region: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/azureml/core/workspace.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(path, auth)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 raise UserErrorException('We could not find config.json in: {} or in its parent directories. '\n\u001b[1;32m    132\u001b[0m                                          \u001b[0;34m'Please provide the full path to the config file or ensure that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                                          'config.json exists in the parent directories.'.format(normalized_path))\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconfig_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUserErrorException\u001b[0m: We could not find config.json in: /home/nbuser/library or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories."
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import BatchAiCompute, ComputeTarget\nfrom azureml.core.datastore import Datastore\nfrom azureml.data.data_reference import DataReference\nfrom azureml.pipeline.core import Pipeline, PipelineData\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.core.runconfig import CondaDependencies, RunConfiguration",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create and attach Compute targets\nNext, create and attach Batch AI compute targets. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\n\n# choose a name for your cluster\nbatchai_cluster_name = os.environ.get(\"BATCHAI_CLUSTER_NAME\", \"gpu-cluster\")\ncluster_min_nodes = os.environ.get(\"BATCHAI_CLUSTER_MIN_NODES\", 0)\ncluster_max_nodes = os.environ.get(\"BATCHAI_CLUSTER_MAX_NODES\", 1)\nvm_size = os.environ.get(\"BATCHAI_CLUSTER_SKU\", \"STANDARD_NC6\")\nautoscale_enabled = os.environ.get(\"BATCHAI_CLUSTER_AUTOSCALE_ENABLED\", True)\n\n\nif batchai_cluster_name in ws.compute_targets:\n    compute_target = ws.compute_targets[batchai_cluster_name]\n    if compute_target and type(compute_target) is BatchAiCompute:\n        print('found compute target. just use it. ' + batchai_cluster_name)\nelse:\n    print('creating a new compute target...')\n    provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = vm_size, # NC6 is GPU-enabled\n                                                                vm_priority = 'lowpriority', # optional\n                                                                autoscale_enabled = autoscale_enabled,\n                                                                cluster_min_nodes = cluster_min_nodes, \n                                                                cluster_max_nodes = cluster_max_nodes)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n    \n    # can poll for a minimum number of nodes and for a specific timeout. \n    # if no min node count is provided it will use the scale settings for the cluster\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n    \n     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n    print(compute_target.status.serialize())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Python scripts to run"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, create the Python scripts that run the batch scoring. The following code creates the script `batchai_score.py` which takes input images in `dataset_path`, pretrained models in `model_dir`, and outputs a `results-label.txt` to `output_dir`."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%writefile $scripts_folder/batchai_score.py\nimport os\nimport argparse\nimport datetime,time\nimport tensorflow as tf\nfrom math import ceil\nimport numpy as np\nimport shutil\nfrom tensorflow.contrib.slim.python.slim.nets import inception_v3\nfrom azureml.core.model import Model\n\nslim = tf.contrib.slim\n\nparser = argparse.ArgumentParser(description=\"Start a tensorflow model serving\")\nparser.add_argument('--model_name', dest=\"model_name\", required=True)\nparser.add_argument('--label_dir', dest=\"label_dir\", required=True)\nparser.add_argument('--dataset_path', dest=\"dataset_path\", required=True)\nparser.add_argument('--output_dir', dest=\"output_dir\", required=True)\nparser.add_argument('--batch_size', dest=\"batch_size\", type=int, required=True)\n\nargs = parser.parse_args()\n\nimage_size = 299\nnum_channel = 3\n\n# create output directory if it does not exist\nos.makedirs(args.output_dir, exist_ok=True)\n\ndef get_class_label_dict(label_file):\n  label = []\n  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n  for l in proto_as_ascii_lines:\n    label.append(l.rstrip())\n  return label\n\n\nclass DataIterator:\n    def __init__(self, data_dir):\n        self.file_paths = []\n        image_list = os.listdir(data_dir)\n        total_size = len(image_list)\n        self.file_paths = [data_dir + '/' + file_name.rstrip() for file_name in image_list ]\n\n        self.labels = [1 for file_name in self.file_paths]\n\n    @property\n    def size(self):\n        return len(self.labels)\n\n    def input_pipeline(self, batch_size):\n        images_tensor = tf.convert_to_tensor(self.file_paths, dtype=tf.string)\n        labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n        input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], shuffle=False)\n        labels = input_queue[1]\n        images_content = tf.read_file(input_queue[0])\n\n        image_reader = tf.image.decode_jpeg(images_content, channels=num_channel, name=\"jpeg_reader\")\n        float_caster = tf.cast(image_reader, tf.float32)\n        new_size = tf.constant([image_size, image_size], dtype=tf.int32)\n        images = tf.image.resize_images(float_caster, new_size)\n        images = tf.divide(tf.subtract(images, [0]), [255])\n\n        image_batch, label_batch = tf.train.batch([images, labels], batch_size=batch_size, capacity=5 * batch_size)\n        return image_batch\n\ndef main(_):\n    start_time = datetime.datetime.now()\n    label_file_name = os.path.join(args.label_dir, \"labels.txt\")\n    label_dict = get_class_label_dict(label_file_name)\n    classes_num = len(label_dict)\n    test_feeder = DataIterator(data_dir=args.dataset_path)\n    total_size = len(test_feeder.labels)\n    count = 0\n    # get model from model registry\n    model_path = Model.get_model_path(args.model_name)\n    with tf.Session() as sess:\n        test_images = test_feeder.input_pipeline(batch_size=args.batch_size)\n        with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n            input_images = tf.placeholder(tf.float32, [args.batch_size, image_size, image_size, num_channel])\n            logits, _ = inception_v3.inception_v3(input_images,\n                                                        num_classes=classes_num,\n                                                        is_training=False)\n            probabilities = tf.argmax(logits, 1)\n\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.local_variables_initializer())\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        saver = tf.train.Saver()\n        saver.restore(sess, model_path)\n        out_filename = os.path.join(args.output_dir, \"result-labels.txt\")\n        with open(out_filename, \"w\") as result_file:\n            i = 0\n            while count < total_size and not coord.should_stop():\n                test_images_batch = sess.run(test_images)\n                file_names_batch = test_feeder.file_paths[i*args.batch_size: min(test_feeder.size, (i+1)*args.batch_size)]\n                results = sess.run(probabilities, feed_dict={input_images: test_images_batch})\n                new_add = min(args.batch_size, total_size-count)\n                count += new_add\n                i += 1\n                for j in range(new_add):\n                    result_file.write(os.path.basename(file_names_batch[j]) + \": \" + label_dict[results[j]] + \"\\n\")\n                result_file.flush()\n            coord.request_stop()\n            coord.join(threads)\n            \n        # copy the file to artifacts\n        shutil.copy(out_filename, \"./outputs/\")\n        # Move the processed data out of the blob so that the next run can process the data.\n\nif __name__ == \"__main__\":\n    tf.app.run()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prepare Model and Input data"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Download Model\n\nNext, download and extract the model from http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz into a folder named `\"models\"`."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# create directory for model\nmodel_dir = 'models'\nif not os.path.isdir(model_dir):\n    os.mkdir(model_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import tarfile\nimport urllib.request\n\nurl=\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\"\nresponse = urllib.request.urlretrieve(url, \"model.tar.gz\")\ntar = tarfile.open(\"model.tar.gz\", \"r:gz\")\ntar.extractall(model_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a datastore that points to blob container containing sample images\n\nWe've created a public blob container that contains images from the ImageNet evaluation set. The container is named `sampledata` on an account named `pipelinedata`. In the next step, we create a datastore with the name `images_datastore` that points to this container. The `overwrite=True` step overwrites any datastore that was created previously with that name. \n\nThis step can be changed to point to your blob container by providing an additional `account_key` parameter with `account_name`. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "account_name = \"pipelinedata\"\nsample_data = Datastore.register_azure_blob_container(ws, datastore_name=\"images_datastore\", container_name=\"sampledata\", \n                                                        account_name=account_name, \n                                                        overwrite=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Output datastore"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We write the outputs to the default datastore"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "default_ds = ws.get_default_datastore()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Specify where the data is stored or will be written to"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.data.data_reference import DataReference\nfrom azureml.pipeline.core import Pipeline, PipelineData\nfrom azureml.core import Datastore\nfrom azureml.core import Experiment",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "input_images = DataReference(datastore=sample_data, \n                             data_reference_name=\"input_images\",\n                             path_on_datastore=\"batchscoring/images\",\n                             mode=\"download\"\n                            )\nmodel_dir = DataReference(datastore=sample_data, \n                          data_reference_name=\"input_model\",\n                          path_on_datastore=\"batchscoring/models\",\n                          mode=\"download\"                          \n                         )\nlabel_dir = DataReference(datastore=sample_data, \n                          data_reference_name=\"input_labels\",\n                          path_on_datastore=\"batchscoring/labels\",\n                          mode=\"download\"                          \n                         )\noutput_dir = PipelineData(name=\"scores\", \n                          datastore=default_ds, \n                          output_path_on_compute=\"batchscoring/results\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Register the model with Workspace"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import shutil\nfrom azureml.core.model import Model\n\n# register downloaded model \nmodel = Model.register(model_path = \"models/inception_v3.ckpt\",\n                       model_name = \"inception\", # this is the name the model is registered as\n                       tags = {'pretrained': \"inception\"},\n                       description = \"Imagenet trained tensorflow inception\",\n                       workspace = ws)\n# remove the downloaded dir after registration if you wish\nshutil.rmtree(\"models\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Specify environment to run the script"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "cd = CondaDependencies.create(pip_packages=[\"tensorflow-gpu==1.4.0\", \"azureml-defaults\"])\n\n# Runconfig\nbatchai_run_config = RunConfiguration(conda_dependencies=cd)\nbatchai_run_config.environment.docker.enabled = True\nbatchai_run_config.environment.docker.gpu_support = True\nbatchai_run_config.environment.docker.base_image = \"microsoft/mmlspark:gpu-0.12\"\nbatchai_run_config.environment.spark.precache_packages = False",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Steps to run"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "A subset of the parameters to the python script can be given as input when we re-run a `PublishedPipeline`. In the current example, we define `batch_size` taken by the script as such parameter."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.core.graph import PipelineParameter\nbatch_size_param = PipelineParameter(name=\"param_batch_size\", default_value=20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "inception_model_name = \"inception_v3.ckpt\"\n\nbatch_score_step = PythonScriptStep(\n    name=\"batch ai scoring\",\n    script_name=\"batchai_score.py\",\n    arguments=[\"--dataset_path\", input_images, \n               \"--model_name\", \"inception\",\n               \"--label_dir\", label_dir, \n               \"--output_dir\", output_dir, \n               \"--batch_size\", batch_size_param],\n    target=compute_target,\n    inputs=[input_images, label_dir],\n    outputs=[output_dir],\n    runconfig=batchai_run_config,\n    source_directory=scripts_folder\n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\npipeline_run = Experiment(ws, 'batch_scoring').submit(pipeline, pipeline_params={\"param_batch_size\": 20})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Monitor run"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.train.widgets import RunDetails\nRunDetails(pipeline_run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "pipeline_run.wait_for_completion(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Download and review output"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "step_run = list(pipeline_run.get_children())[0]\nstep_run.download_file(\"./outputs/result-labels.txt\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.read_csv(\"result-labels.txt\", delimiter=\":\", header=None)\ndf.columns = [\"Filename\", \"Prediction\"]\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Publish a pipeline and rerun using a REST call"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create a published pipeline"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "published_pipeline = pipeline_run.publish_pipeline(\n    name=\"Inception v3 scoring\", description=\"Batch scoring using Inception v3 model\", version=\"1.0\")\n\npublished_id = published_pipeline.id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Rerun using REST call"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Get AAD token"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.authentication import AzureCliAuthentication\nimport requests\n\ncli_auth = AzureCliAuthentication()\naad_token = cli_auth.get_authentication_header()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Run published pipeline using its REST endpoint"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.core import PublishedPipeline\n\nrest_endpoint = published_pipeline.endpoint\n# specify batch size when running the pipeline\nresponse = requests.post(rest_endpoint, \n                         headers=aad_token, \n                         json={\"ExperimentName\": \"batch_scoring\",\n                               \"ParameterAssignments\": {\"param_batch_size\": 50}})\nrun_id = response.json()[\"Id\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Monitor the new run"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.pipeline.core.run import PipelineRun\npublished_pipeline_run = PipelineRun(ws.experiments[\"batch_scoring\"], run_id)\n\nRunDetails(published_pipeline_run).show()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "hichando"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
