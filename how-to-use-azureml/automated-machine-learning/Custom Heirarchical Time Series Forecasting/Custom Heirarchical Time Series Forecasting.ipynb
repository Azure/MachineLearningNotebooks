{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1634367644354
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "import logging\n",
    "from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
    "\n",
    "class Runner:\n",
    "    def __init__(self,train_df_path,date_var,hr_vars,freq,holiday_feature,target_var):\n",
    "        self.df = pd.read_csv('train.csv')\n",
    "        self.freq = freq\n",
    "        self.target_var = target_var\n",
    "        self.date_time_var = date_var\n",
    "        self.df[date_var] = pd.to_datetime(self.df[date_var])\n",
    "        self.hr_vars = hr_vars\n",
    "        self.holiday = holiday_feature\n",
    "        self.suggestion = {}\n",
    "        for x in self.hr_vars:\n",
    "            self.suggestion[x] = list(self.df[x].unique())\n",
    "            \n",
    "        self.job_cache={}\n",
    "\n",
    "    def _get_suggestions(self):\n",
    "        return self.suggestion\n",
    "\n",
    "    def _create_job(self,config_list,test_df_path):\n",
    "        self.config_list = config_list\n",
    "\n",
    "        key_val = \"_\"\n",
    "        for x in config_list:\n",
    "            key_val = key_val+\"_\"+x[0]+\"_\"+str(x[1])\n",
    "            \n",
    "        \n",
    "        \n",
    "        print(\"Check if Key Exists in Job Cache\")\n",
    "        if key_val in self.job_cache.keys():\n",
    "            \n",
    "            return key_val\n",
    "        \n",
    "        else:\n",
    "            #Perform Slicing\n",
    "            final_df = self.df\n",
    "            for x in config_list:\n",
    "                final_df = final_df[final_df[x[0]]==x[1]]\n",
    "            self.final_df = final_df\n",
    "            path = key_val+\".csv\"\n",
    "            final_df.to_csv(path)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            train_data = pd.read_csv(path)\n",
    "            \n",
    "            forecasting_parameters = ForecastingParameters(time_column_name=self.date_time_var, \n",
    "                                               forecast_horizon=50,\n",
    "                                               country_or_region_for_holidays='US',\n",
    "                                               \n",
    "                                               freq=self.freq,\n",
    "                                               target_lags='auto',\n",
    "                                               target_rolling_window_size=10)\n",
    "            \n",
    "            automl_config = AutoMLConfig(task='forecasting',\n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             experiment_timeout_minutes=15,\n",
    "                             enable_early_stopping=True,\n",
    "                             training_data=train_data,\n",
    "                             label_column_name=self.target_var,\n",
    "                             n_cross_validations=5,\n",
    "                             enable_ensembling=False,\n",
    "                             verbosity=logging.INFO,\n",
    "                             forecasting_parameters = forecasting_parameters)\n",
    "            ws = Workspace.from_config()\n",
    "            experiment = Experiment(ws, \"local-Delta\")\n",
    "            local_run = experiment.submit(automl_config, show_output=True)\n",
    "            print(\"Training Job Complete\")\n",
    "            best_run, fitted_model = local_run.get_output()\n",
    "            print(\"Making Predictions\")\n",
    "\n",
    "\n",
    "            \n",
    "            self.job_cache[key_val] = fitted_model\n",
    "            print(\"Finish\")\n",
    "            return key_val\n",
    "\n",
    "\n",
    "    def _predict(self,test_df_path,key_val):\n",
    "        test_df = pd.read_csv(test_df_path)\n",
    "        fitted_model = self.job_cache[key_val]\n",
    "        print(\"Slicing Test Data\")\n",
    "        for x in self.config_list:\n",
    "            test_df = test_df[test_df[x[0]]==x[1]]\n",
    "        final_test_df = test_df\n",
    "        test_path = key_val+\"test_df\"+\".csv\"\n",
    "        final_test_df.to_csv(test_path)\n",
    "        print(\"Test Data Slicing Finish\")\n",
    "        test_data = pd.read_csv(test_path)\n",
    "        test_labels = test_data[self.config_list[0][0]].to_numpy()\n",
    "        label_query = test_labels.copy().astype(np.float)\n",
    "        print(\"Creating Query\")\n",
    "        label_query.fill(np.nan)\n",
    "        fitted_model.quantiles = [0.05,0.5, 0.9,0.75]\n",
    "        result=fitted_model.forecast_quantiles(test_data,label_query,ignore_data_errors=True)\n",
    "        print(\"Finish\")\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1634367646250
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "r = Runner(train_df_path='train.csv',date_var='Date',target_var='Weekly_Sales',holiday_feature=True,hr_vars=['Store','Dept'],freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1634367648503
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Store': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45],\n",
       " 'Dept': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  67,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  87,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  39,\n",
       "  50,\n",
       "  43,\n",
       "  65]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r._get_suggestions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1634368691086
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if Key Exists in Job Cache\n",
      "No run_configuration provided, running on local with default configuration\n",
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>local-Delta</td><td>AutoML_81be0f7a-d6b4-40fc-b725-2575828f76af</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_81be0f7a-d6b4-40fc-b725-2575828f76af?wsid=/subscriptions/c8204c65-7397-4888-a397-a21bc631464e/resourcegroups/ml-resource-grp/workspaces/ml-studio&amp;tid=638c2807-f86c-4538-9f10-19623d30686b\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Heuristic parameters: Target_Lag = '[0]'.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Short series handling\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n",
      "              \n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Frequency detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n",
      "              \n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Memory Issues Detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  The selected horizon, lag and rolling window values were analyzed, and no potential memory issues were detected.\n",
      "              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   Naive                                          0:00:46       0.1820    0.1820\n",
      "         1   SeasonalNaive                                  0:00:34       0.2126    0.1820\n",
      "         2   Average                                        0:00:33       0.1565    0.1565\n",
      "         3   SeasonalAverage                                0:00:34       0.2046    0.1565\n",
      "         4   ExponentialSmoothing                           0:00:52       0.1820    0.1565\n",
      "         5   Arimax                                         0:01:17       0.1475    0.1475\n",
      "         6   ProphetModel                                   0:00:59       0.1643    0.1475\n",
      "         7   StandardScalerWrapper LightGBM                 0:00:22       0.1412    0.1412\n",
      "         8   StandardScalerWrapper XGBoostRegressor         0:00:32       0.1431    0.1412\n",
      "         9   MaxAbsScaler ElasticNet                        0:00:28       0.1518    0.1412\n",
      "        10   RobustScaler ElasticNet                        0:00:26       0.1508    0.1412\n",
      "        11   MinMaxScaler ElasticNet                        0:00:27       0.1528    0.1412\n",
      "        12   StandardScalerWrapper ElasticNet               0:00:26       0.1535    0.1412\n",
      "        13   MinMaxScaler RandomForest                      0:00:26       0.1341    0.1341\n",
      "        14   MaxAbsScaler ElasticNet                        0:00:27       0.1526    0.1341\n",
      "        15   StandardScalerWrapper ElasticNet               0:00:28       0.1535    0.1341\n",
      "        16   MaxAbsScaler ElasticNet                        0:00:27       0.1535    0.1341\n",
      "        17   StandardScalerWrapper ElasticNet               0:00:26       0.1526    0.1341\n",
      "        18   MinMaxScaler ExtremeRandomTrees                0:00:25       0.1567    0.1341\n",
      "        19   MinMaxScaler RandomForest                      0:00:28       0.1389    0.1341\n",
      "        20   MinMaxScaler ExtremeRandomTrees                0:00:26       0.1489    0.1341\n",
      "        21   MinMaxScaler ExtremeRandomTrees                0:00:25       0.1298    0.1298\n",
      "        22   MaxAbsScaler ExtremeRandomTrees                0:00:26       0.1543    0.1298\n",
      "        23   MinMaxScaler DecisionTree                      0:00:25       0.1367    0.1298\n",
      "        24   RobustScaler ExtremeRandomTrees                0:00:26       0.1196    0.1196\n",
      "        25   StandardScalerWrapper ExtremeRandomTrees       0:00:27       0.1326    0.1196\n",
      "        26   RobustScaler DecisionTree                      0:00:26       0.1440    0.1196\n",
      "Stopping criteria reached at iteration 27. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n",
      "Training Job Complete\n",
      "Making Predictions\n",
      "Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:interpret_community.common.explanation_utils:Using default datastore for uploads\n"
     ]
    }
   ],
   "source": [
    "k = r._create_job(config_list=[('Store',1),('Dept',2)],test_df_path='test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1634368779645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing Test Data\n",
      "Test Data Slicing Finish\n",
      "Creating Query\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "final_res = r._predict(test_df_path='test.csv',key_val=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1634368781234
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>44586.91</td>\n",
       "      <td>47054.11</td>\n",
       "      <td>48976.38</td>\n",
       "      <td>48065.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>nan</td>\n",
       "      <td>45977.22</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>nan</td>\n",
       "      <td>44166.71</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-23</td>\n",
       "      <td>nan</td>\n",
       "      <td>45329.02</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>nan</td>\n",
       "      <td>46826.61</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>nan</td>\n",
       "      <td>47397.65</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-12-14</td>\n",
       "      <td>nan</td>\n",
       "      <td>51093.88</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>nan</td>\n",
       "      <td>56250.88</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>33286.82</td>\n",
       "      <td>44498.70</td>\n",
       "      <td>53234.19</td>\n",
       "      <td>49096.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>nan</td>\n",
       "      <td>48210.70</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>nan</td>\n",
       "      <td>44743.39</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>nan</td>\n",
       "      <td>42993.85</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>nan</td>\n",
       "      <td>42598.71</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>nan</td>\n",
       "      <td>51056.51</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>nan</td>\n",
       "      <td>49026.14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>32714.08</td>\n",
       "      <td>46445.77</td>\n",
       "      <td>57144.51</td>\n",
       "      <td>52076.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>nan</td>\n",
       "      <td>46246.75</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>nan</td>\n",
       "      <td>51210.56</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>nan</td>\n",
       "      <td>48934.33</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-03-15</td>\n",
       "      <td>nan</td>\n",
       "      <td>45928.01</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>nan</td>\n",
       "      <td>45414.32</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>nan</td>\n",
       "      <td>46696.65</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>33461.61</td>\n",
       "      <td>49317.60</td>\n",
       "      <td>61671.44</td>\n",
       "      <td>55819.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>nan</td>\n",
       "      <td>45739.74</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-04-19</td>\n",
       "      <td>nan</td>\n",
       "      <td>45023.39</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>nan</td>\n",
       "      <td>45089.85</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>nan</td>\n",
       "      <td>50097.75</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-05-10</td>\n",
       "      <td>nan</td>\n",
       "      <td>47722.23</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>nan</td>\n",
       "      <td>44775.21</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>27716.73</td>\n",
       "      <td>45444.27</td>\n",
       "      <td>59256.29</td>\n",
       "      <td>52713.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>46031.58</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>nan</td>\n",
       "      <td>48531.90</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>nan</td>\n",
       "      <td>45417.55</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>nan</td>\n",
       "      <td>45451.98</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>nan</td>\n",
       "      <td>46276.86</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>nan</td>\n",
       "      <td>48863.09</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>25909.69</td>\n",
       "      <td>45329.23</td>\n",
       "      <td>60459.54</td>\n",
       "      <td>53292.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>nan</td>\n",
       "      <td>44752.12</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>nan</td>\n",
       "      <td>45207.80</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     0.05      0.5      0.9     0.75\n",
       "0  2012-11-02 44586.91 47054.11 48976.38 48065.81\n",
       "1  2012-11-09      nan 45977.22      nan      nan\n",
       "2  2012-11-16      nan 44166.71      nan      nan\n",
       "3  2012-11-23      nan 45329.02      nan      nan\n",
       "4  2012-11-30      nan 46826.61      nan      nan\n",
       "5  2012-12-07      nan 47397.65      nan      nan\n",
       "6  2012-12-14      nan 51093.88      nan      nan\n",
       "7  2012-12-21      nan 56250.88      nan      nan\n",
       "8  2012-12-28 33286.82 44498.70 53234.19 49096.25\n",
       "9  2013-01-04      nan 48210.70      nan      nan\n",
       "10 2013-01-11      nan 44743.39      nan      nan\n",
       "11 2013-01-18      nan 42993.85      nan      nan\n",
       "12 2013-01-25      nan 42598.71      nan      nan\n",
       "13 2013-02-01      nan 51056.51      nan      nan\n",
       "14 2013-02-08      nan 49026.14      nan      nan\n",
       "15 2013-02-15 32714.08 46445.77 57144.51 52076.59\n",
       "16 2013-02-22      nan 46246.75      nan      nan\n",
       "17 2013-03-01      nan 51210.56      nan      nan\n",
       "18 2013-03-08      nan 48934.33      nan      nan\n",
       "19 2013-03-15      nan 45928.01      nan      nan\n",
       "20 2013-03-22      nan 45414.32      nan      nan\n",
       "21 2013-03-29      nan 46696.65      nan      nan\n",
       "22 2013-04-05 33461.61 49317.60 61671.44 55819.51\n",
       "23 2013-04-12      nan 45739.74      nan      nan\n",
       "24 2013-04-19      nan 45023.39      nan      nan\n",
       "25 2013-04-26      nan 45089.85      nan      nan\n",
       "26 2013-05-03      nan 50097.75      nan      nan\n",
       "27 2013-05-10      nan 47722.23      nan      nan\n",
       "28 2013-05-17      nan 44775.21      nan      nan\n",
       "29 2013-05-24 27716.73 45444.27 59256.29 52713.63\n",
       "30 2013-05-31      nan 46031.58      nan      nan\n",
       "31 2013-06-07      nan 48531.90      nan      nan\n",
       "32 2013-06-14      nan 45417.55      nan      nan\n",
       "33 2013-06-21      nan 45451.98      nan      nan\n",
       "34 2013-06-28      nan 46276.86      nan      nan\n",
       "35 2013-07-05      nan 48863.09      nan      nan\n",
       "36 2013-07-12 25909.69 45329.23 60459.54 53292.42\n",
       "37 2013-07-19      nan 44752.12      nan      nan\n",
       "38 2013-07-26      nan 45207.80      nan      nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1634368796032
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if Key Exists in Job Cache\n"
     ]
    }
   ],
   "source": [
    "k = r._create_job(config_list=[('Store',1),('Dept',2)],test_df_path='test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1634369803503
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if Key Exists in Job Cache\n",
      "No run_configuration provided, running on local with default configuration\n",
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>local-Delta</td><td>AutoML_346e57b7-8b92-47a1-9a79-92d6a3566ee6</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_346e57b7-8b92-47a1-9a79-92d6a3566ee6?wsid=/subscriptions/c8204c65-7397-4888-a397-a21bc631464e/resourcegroups/ml-resource-grp/workspaces/ml-studio&amp;tid=638c2807-f86c-4538-9f10-19623d30686b\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Heuristic parameters: Target_Lag = '[0]'.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "Current status: DatasetFeaturization. Beginning to featurize the CV split.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Short series handling\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n",
      "              \n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Frequency detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n",
      "              \n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Memory Issues Detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  The selected horizon, lag and rolling window values were analyzed, and no potential memory issues were detected.\n",
      "              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   Naive                                          0:00:33       0.3105    0.3105\n",
      "         1   SeasonalNaive                                  0:00:34       0.3085    0.3085\n",
      "         2   Average                                        0:00:45       0.3722    0.3085\n",
      "         3   SeasonalAverage                                0:00:34       0.3083    0.3083\n",
      "         4   ExponentialSmoothing                           0:00:52       0.3071    0.3071\n",
      "         5   Arimax                                         0:01:10       0.2952    0.2952\n",
      "         6   ProphetModel                                   0:01:26       0.1036    0.1036\n",
      "         7   StandardScalerWrapper LightGBM                 0:00:38       0.3236    0.1036\n",
      "         8   StandardScalerWrapper XGBoostRegressor         0:00:31       0.2759    0.1036\n",
      "         9   MaxAbsScaler ElasticNet                        0:00:39       0.1544    0.1036\n",
      "        10   RobustScaler ElasticNet                        0:00:26       0.1291    0.1036\n",
      "        11   MinMaxScaler ElasticNet                        0:00:27       0.1385    0.1036\n",
      "        12   StandardScalerWrapper ElasticNet               0:00:27       0.1406    0.1036\n",
      "        13   MinMaxScaler RandomForest                      0:00:27       0.1316    0.1036\n",
      "        14   MaxAbsScaler ElasticNet                        0:00:28       0.1560    0.1036\n",
      "        15   StandardScalerWrapper ElasticNet               0:00:27       0.1405    0.1036\n",
      "        16   MaxAbsScaler ElasticNet                        0:00:27       0.1406    0.1036\n",
      "        17   StandardScalerWrapper ElasticNet               0:00:26       0.1358    0.1036\n",
      "        18   MinMaxScaler ExtremeRandomTrees                0:00:26       0.1017    0.1017\n",
      "        19   MinMaxScaler RandomForest                      0:00:28       0.0642    0.0642\n",
      "        20   MinMaxScaler ExtremeRandomTrees                0:00:28       0.0936    0.0642\n",
      "        21   MinMaxScaler ExtremeRandomTrees                0:00:26       0.2246    0.0642\n",
      "        22   MaxAbsScaler ExtremeRandomTrees                0:00:27       0.0993    0.0642\n",
      "        23   MinMaxScaler DecisionTree                      0:00:38       0.1624    0.0642\n",
      "Stopping criteria reached at iteration 24. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n",
      "Training Job Complete\n",
      "Making Predictions\n",
      "Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /metric/v2.0/subscriptions/c8204c65-7397-4888-a397-a21bc631464e/resourceGroups/ml-resource-grp/providers/Microsoft.MachineLearningServices/workspaces/ml-studio/runs/AutoML_346e57b7-8b92-47a1-9a79-92d6a3566ee6_9/full\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6fa86b5780>: Failed to establish a new connection: [Errno 111] Connection refused',)': /metric/v2.0/subscriptions/c8204c65-7397-4888-a397-a21bc631464e/resourceGroups/ml-resource-grp/providers/Microsoft.MachineLearningServices/workspaces/ml-studio/runs/AutoML_346e57b7-8b92-47a1-9a79-92d6a3566ee6_13/full\n",
      "INFO:interpret_community.common.explanation_utils:Using default datastore for uploads\n"
     ]
    }
   ],
   "source": [
    "k = r._create_job(config_list=[('Store',3),('Dept',5)],test_df_path='test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1634369866254
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing Test Data\n",
      "Test Data Slicing Finish\n",
      "Creating Query\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "final_res_s3_d5 = r._predict(test_df_path='test.csv',key_val=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1634369872331
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>6381.53</td>\n",
       "      <td>10053.93</td>\n",
       "      <td>12915.19</td>\n",
       "      <td>11559.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>nan</td>\n",
       "      <td>10372.03</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>nan</td>\n",
       "      <td>10446.52</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-23</td>\n",
       "      <td>nan</td>\n",
       "      <td>40743.43</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>nan</td>\n",
       "      <td>17359.45</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>nan</td>\n",
       "      <td>17134.28</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-12-14</td>\n",
       "      <td>nan</td>\n",
       "      <td>19585.18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>nan</td>\n",
       "      <td>20337.18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>12494.40</td>\n",
       "      <td>18129.85</td>\n",
       "      <td>22520.58</td>\n",
       "      <td>20440.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>nan</td>\n",
       "      <td>12583.31</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>nan</td>\n",
       "      <td>9949.62</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>nan</td>\n",
       "      <td>9176.32</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>nan</td>\n",
       "      <td>10329.34</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>nan</td>\n",
       "      <td>15021.18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>nan</td>\n",
       "      <td>14657.37</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>5232.05</td>\n",
       "      <td>12134.03</td>\n",
       "      <td>17511.56</td>\n",
       "      <td>14964.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>nan</td>\n",
       "      <td>12074.88</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>nan</td>\n",
       "      <td>12650.55</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>nan</td>\n",
       "      <td>11154.43</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-03-15</td>\n",
       "      <td>nan</td>\n",
       "      <td>11203.14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>nan</td>\n",
       "      <td>11446.33</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>nan</td>\n",
       "      <td>13165.18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>2299.39</td>\n",
       "      <td>10269.12</td>\n",
       "      <td>16478.55</td>\n",
       "      <td>13537.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>nan</td>\n",
       "      <td>9580.63</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-04-19</td>\n",
       "      <td>nan</td>\n",
       "      <td>9383.45</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>nan</td>\n",
       "      <td>9087.05</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>nan</td>\n",
       "      <td>10196.07</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-05-10</td>\n",
       "      <td>nan</td>\n",
       "      <td>10257.78</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>nan</td>\n",
       "      <td>10142.35</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>411.79</td>\n",
       "      <td>9322.21</td>\n",
       "      <td>16264.57</td>\n",
       "      <td>12976.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>nan</td>\n",
       "      <td>9653.09</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>nan</td>\n",
       "      <td>10308.30</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>nan</td>\n",
       "      <td>10392.22</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>nan</td>\n",
       "      <td>9921.43</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>nan</td>\n",
       "      <td>10142.80</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>nan</td>\n",
       "      <td>10206.66</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>-586.21</td>\n",
       "      <td>9174.67</td>\n",
       "      <td>16779.65</td>\n",
       "      <td>13177.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>nan</td>\n",
       "      <td>9116.13</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>nan</td>\n",
       "      <td>8742.26</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     0.05      0.5      0.9     0.75\n",
       "0  2012-11-02  6381.53 10053.93 12915.19 11559.83\n",
       "1  2012-11-09      nan 10372.03      nan      nan\n",
       "2  2012-11-16      nan 10446.52      nan      nan\n",
       "3  2012-11-23      nan 40743.43      nan      nan\n",
       "4  2012-11-30      nan 17359.45      nan      nan\n",
       "5  2012-12-07      nan 17134.28      nan      nan\n",
       "6  2012-12-14      nan 19585.18      nan      nan\n",
       "7  2012-12-21      nan 20337.18      nan      nan\n",
       "8  2012-12-28 12494.40 18129.85 22520.58 20440.73\n",
       "9  2013-01-04      nan 12583.31      nan      nan\n",
       "10 2013-01-11      nan  9949.62      nan      nan\n",
       "11 2013-01-18      nan  9176.32      nan      nan\n",
       "12 2013-01-25      nan 10329.34      nan      nan\n",
       "13 2013-02-01      nan 15021.18      nan      nan\n",
       "14 2013-02-08      nan 14657.37      nan      nan\n",
       "15 2013-02-15  5232.05 12134.03 17511.56 14964.26\n",
       "16 2013-02-22      nan 12074.88      nan      nan\n",
       "17 2013-03-01      nan 12650.55      nan      nan\n",
       "18 2013-03-08      nan 11154.43      nan      nan\n",
       "19 2013-03-15      nan 11203.14      nan      nan\n",
       "20 2013-03-22      nan 11446.33      nan      nan\n",
       "21 2013-03-29      nan 13165.18      nan      nan\n",
       "22 2013-04-05  2299.39 10269.12 16478.55 13537.19\n",
       "23 2013-04-12      nan  9580.63      nan      nan\n",
       "24 2013-04-19      nan  9383.45      nan      nan\n",
       "25 2013-04-26      nan  9087.05      nan      nan\n",
       "26 2013-05-03      nan 10196.07      nan      nan\n",
       "27 2013-05-10      nan 10257.78      nan      nan\n",
       "28 2013-05-17      nan 10142.35      nan      nan\n",
       "29 2013-05-24   411.79  9322.21 16264.57 12976.02\n",
       "30 2013-05-31      nan  9653.09      nan      nan\n",
       "31 2013-06-07      nan 10308.30      nan      nan\n",
       "32 2013-06-14      nan 10392.22      nan      nan\n",
       "33 2013-06-21      nan  9921.43      nan      nan\n",
       "34 2013-06-28      nan 10142.80      nan      nan\n",
       "35 2013-07-05      nan 10206.66      nan      nan\n",
       "36 2013-07-12  -586.21  9174.67 16779.65 13177.23\n",
       "37 2013-07-19      nan  9116.13      nan      nan\n",
       "38 2013-07-26      nan  8742.26      nan      nan"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res_s3_d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
