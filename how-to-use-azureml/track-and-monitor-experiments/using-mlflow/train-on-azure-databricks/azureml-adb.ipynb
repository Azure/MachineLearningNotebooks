{
	"cells": [
		{
			"cell_type": "markdown",
			"source": [
				"Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
			],
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": [
				"## Use MLflow with Azure Machine Learning\n\nThis example shows you how to use MLflow with Azure Machine Learning services. You'll learn how to:\n\n 1. Set up MLflow tracking URI to Azure ML\n 2. Create MLflow experiment\n 3. Train a PyTorch model on Azure Databricks while logging metrics and artifacts\n 4. View your experiment within your Azure ML Workspace in Azure Portal.\n 5. Deploy the Model to ACI/AKS\n \n*This PyTorch notebook requires Python 3.6.x and torch, torchvision and pillow for Training & Deployment. Please install it on your training cluster before proceeding.*"
			],
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": [
				"## High level overview\n\nInstall *azureml-mlflow* package before running this notebook on your cluster. This single package includes MLflow and Azure ML SDK."
			],
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": [
				"![MLflow-AzureML](https://raw.githubusercontent.com/parasharshah/mlflow-azureml/master/MLflow%20with%20Azure%20ML.jpg)"
			],
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": [
				"import mlflow\nimport mlflow.azureml\nimport azureml.mlflow\nimport azureml.core\n\nfrom azureml.core import Workspace\n\nfrom azureml.mlflow import get_portal_url\n\nprint(\"SDK version:\", azureml.core.VERSION)\nprint(\"MLflow version:\", mlflow.version.VERSION)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 5
		},
		{
			"cell_type": "code",
			"source": [
				"subscription_id = \"74eccef0-4b8d-4f83-b5f9-fa100d155b22\" #you should be owner or contributor\nresource_group = \"namikhai-test-rg\" #you should be owner or contributor\nworkspace_name = \"AMLTest99\"              # your workspace name - needs to be unique - can be anything"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 6
		},
		{
			"cell_type": "code",
			"source": [
				"ws = Workspace.get(name = workspace_name,\n                      subscription_id = subscription_id,\n                      resource_group = resource_group)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 7
		},
		{
			"cell_type": "markdown",
			"source": [
				"## Set Your Tracking URL Using Your Workspace\nLink the MLflow tracking to Azure ML Workspace.  After this, all your experiments will land in the managed AzureML tracking service."
			],
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": [
				"tracking_uri = \"adbazureml://westus2.experiments.azureml.net/history/v1.0/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourceGroups/namikhai-test-rg/providers/Microsoft.MachineLearningServices/workspaces/AMLTest99\"\nmlflow.set_tracking_uri(tracking_uri)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 9
		},
		{
			"cell_type": "markdown",
			"source": [
				"## Create an Experiment and Train on Azure Databricks\n\nIn both MLflow and Azure ML, training runs are grouped into experiments. Let's create one for our experimentation.  We'll use pytorch to train MNIST, because, well it's basically required.\n\n![MNIST](https://docs.azuredatabricks.net/_images/mnist.png)"
			],
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": [
				"experiment_name = \"/Users/namikhai@microsoft.com/pytorch-with-mlflow\"\nmlflow.set_experiment(experiment_name)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 11
		},
		{
			"cell_type": "code",
			"source": [
				"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport cloudpickle\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\n\nPREDICTION_DATA_TENSOR_LABEL = None"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 12
		},
		{
			"cell_type": "code",
			"source": [
				"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4*4*50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 1, 28, 28) # Added the view for reshaping score requests\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4*4*50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n    \ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            #####################################\n            # LOG METRICS WITH MLFLOW to Azure ML\n            #####################################\n            mlflow.log_metric(\"epoch_loss\", loss.item())\n\ndef test(args, model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            \n            # For convenience, store a batch of images for scoring later\n            global PREDICTION_DATA_TENSOR_LABEL\n            if PREDICTION_DATA_TENSOR_LABEL is None:\n                PREDICTION_DATA_TENSOR_LABEL = data, data.view(len(data), data.shape[1]* data.shape[2] * data.shape[3]), target\n                \n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    ###########################################\n    # LOG METRIC WITH MLFLOW\n    ###########################################\n    mlflow.log_metric(\"average_loss\", test_loss)\n\n"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 13
		},
		{
			"cell_type": "code",
			"source": [
				"class Args(object):\n  pass\n\n# Training settings\nargs = Args()\nsetattr(args, 'batch_size', 64)\nsetattr(args, 'test_batch_size', 1000)\nsetattr(args, 'epochs', 3) # Higher number for better convergence\nsetattr(args, 'lr', 0.01)\nsetattr(args, 'momentum', 0.5)\nsetattr(args, 'no_cuda', True)\nsetattr(args, 'seed', 1)\nsetattr(args, 'log_interval', 50)\nsetattr(args, 'save_model', True)\n\nuse_cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\n\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=False, **kwargs)\n\nMODEL_SAVE_PATH = 'pytorchmodel'"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 14
		},
		{
			"cell_type": "code",
			"source": [
				"################################\n# START MLFLOW EXPERIMENT\n################################\nwith mlflow.start_run() as run:\n    displayHTML(\"<a href={} target='_blank'>Azure Portal Run Details Page: {}</a>\".format(get_portal_url(run), run.info.run_uuid))\n    model = Net().to(device)\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch)\n        test(args, model, device, test_loader)\n\n    if args.save_model:\n        \n        #create a conda env file which has requirement frameworks\n        from mlflow.utils.environment import _mlflow_conda_env\n        model_env = _mlflow_conda_env(\n            additional_pip_deps=[\n                \"cloudpickle=={}\".format(cloudpickle.__version__),\n                \"torch=={}\".format(torch.__version__),\n                \"torchvision=={}\".format(torchvision.__version__),\n                \"pillow=={}\".format(\"6.0.0\")\n            ]\n        )\n        #############################\n        # LOG MODEL USING MLFLOW\n        #############################\n        import mlflow.pytorch\n        mlflow.pytorch.log_model(model, MODEL_SAVE_PATH, conda_env=model_env)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 15
		},
		{
			"cell_type": "markdown",
			"source": [
				"![Workspace](https://github.com/parasharshah/automl-handson/raw/master/image4deploy.JPG)"
			],
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": [
				"####################################################\n# Retreive id from experiment to deploy\n####################################################\nrunid = run.info.run_id"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 17
		},
		{
			"cell_type": "code",
			"source": [
				"####################################################\n# Build an Azure ML Container Image for an MLflow \n####################################################\n\nazure_image, azure_model = mlflow.azureml.build_image(model_uri='runs:/{}/{}'.format(runid, MODEL_SAVE_PATH),\n                                                      workspace=ws,\n                                                      model_name='pytorch_mnist',\n                                                      image_name='pytorch-mnist-img',\n                                                      synchronous=True)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 18
		},
		{
			"cell_type": "code",
			"source": [
				"from azureml.core.webservice import AciWebservice, Webservice\n\nimport random\nimport string\ndeployment_stub = ''.join([random.choice(string.ascii_lowercase) for i in range(5)])\n\naci_config = AciWebservice.deploy_configuration(cpu_cores=2, \n                                                memory_gb=5, \n                                                tags={\"data\": \"RUL\",  \"method\" : \"pytorch\"}, \n                                                description='Predict using webservice',\n                                                location='westus2')\n\n\n# Deploy the image to Azure Container Instances (ACI) for real-time serving\nwebservice = Webservice.deploy_from_image(\n    image=azure_image, workspace=ws, name=\"mlflow-demo-\"+deployment_stub, deployment_config=aci_config)\n\nwebservice.wait_for_deployment()"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 19
		},
		{
			"cell_type": "code",
			"source": [
				"# After the image deployment completes, requests can be posted via HTTP to the new ACI\n# webservice's scoring URI.\nprint(\"Scoring URI is: {}\".format(webservice.scoring_uri))"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 20
		},
		{
			"cell_type": "code",
			"source": [
				"data, tensor, label = PREDICTION_DATA_TENSOR_LABEL\nTEST_DATA = datasets.MNIST('../data', train=False)\n\nimport base64\nfrom io import BytesIO\n\ndef show_index(index):\n    global TEST_DATA\n    image, label = TEST_DATA[index]\n    buffered = BytesIO()\n    image.save(buffered, format=\"JPEG\")\n    img_str = base64.b64encode(buffered.getvalue())\n    displayHTML('<img src=\"data:image/jpeg;base64,{}\" style=\"width:100px;height:120px;\"\">'.format(img_str.decode('utf-8')))"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 21
		},
		{
			"cell_type": "code",
			"source": [
				"import requests\nimport json\n\ndef score_index(index):\n    sample_input = {\n        \"data\": [tensor[index].tolist()]\n    }\n\n    response = requests.post(\n                  url=webservice.scoring_uri, data=json.dumps(sample_input),\n                  headers={\"Content-type\": \"application/json\"})\n    \n    response_json = json.loads(response.text)\n    scores = response_json[0]\n    max_score = max(scores.values())\n    all_predicted_labels = [x for x , y in scores.items() if y == max_score]\n    displayHTML('<h3>Predicted Digit: {}</h3>'.format(all_predicted_labels[0]))\n"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 22
		},
		{
			"cell_type": "code",
			"source": [
				"#There are 1000 examples in our test set for the MNIST image recognition challenge\n#Pick one at random and display it\nindexpred = 498\nshow_index(indexpred)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 23
		},
		{
			"cell_type": "code",
			"source": [
				"#Then use the model you deployed to a REST endpoint to test it\nscore_index(indexpred)"
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 24
		},
		{
			"cell_type": "code",
			"source": [
				""
			],
			"metadata": {},
			"outputs": [],
			"execution_count": 25
		}
	],
	"metadata": {
		"language_info": {
			"mimetype": "text/x-python",
			"name": "python",
			"pygments_lexer": "ipython3",
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"version": "3.6.5",
			"nbconvert_exporter": "python",
			"file_extension": ".py"
		},
		"name": "mlflow-sparksummit-pytorch_ps",
		"notebookId": 3606421338730397,
		"kernelspec": {
			"display_name": "Python 3.6",
			"language": "python",
			"name": "python36"
		},
		"authors": [
			{
				"name": "roastala"
			}
		]
	},
	"nbformat": 4,
	"nbformat_minor": 0
}