{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Azure Machine Learning Pipelines\n",
    "\n",
    "This notebook supports the document [Tutorial: Schedule machine learning pipelines with Azure Machine Learning SDK for Python](https://docs.microsoft.com/azure/machine-learning/service/tutorial-pipeline-schedule). Please refer to that document for a detailed explanation.\n",
    "\n",
    "The purpose is to programmatically schedule a pipeline to run on Azure. The sample is a data manipulation task that simulates preprocessing and runs every few minutes. Of course, a real data preprocessing step would presumably take much longer to run and would only be run once or perhaps twice a day as new data accumulated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain\n",
    "\n",
    "The fake domain of this tutorial relates to colors. We are pretending that our input data consists of a set of \"votes\" for a color that we need to preprocess for our downstream ML system. The following cells write a domain file **color.py** file, then runs it, and show its basic (silly) functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing color.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile color.py\n",
    "from enum import Enum, unique\n",
    "import numpy as np\n",
    "\n",
    "@unique\n",
    "class Color(Enum) : \n",
    "    Red = 0 \n",
    "    Orange = 1 \n",
    "    Yellow = 2\n",
    "    Green = 3\n",
    "    Blue = 4\n",
    "    Indigo = 5\n",
    "    Violet = 6\n",
    "\n",
    "    @classmethod\n",
    "    def randn_color(cls) : \n",
    "        v = np.random.randn()\n",
    "        c = next((c for c in Color if v < (0.65 * (float(c.value) - 2.5))), Color.Violet)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the file we just wrote in order to validate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run color.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that our method `randn_color()` produces a normally-distributed shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = list(Color.randn_color().value for _ in range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 51., 115., 198., 239., 211., 118.,  68.]),\n",
       " array([0.        , 0.85714286, 1.71428571, 2.57142857, 3.42857143,\n",
       "        4.28571429, 5.14285714, 6.        ]),\n",
       " <a list of 7 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cs,len(Color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and preprocessing data\n",
    "\n",
    "This section writes our **preprocessing.py** file. \n",
    "\n",
    "To simulate some out-of-process data collection, the file **preprocessing.py** generates fake data and writes it to a file **unprocessed_data.csv**. \n",
    "\n",
    "Then, **preprocessing.py** reads that file, and \"prepares the data for ML.\" In this case, it does some data transformation and normalizes the results. It writes the results to **processed_data.csv**. \n",
    "\n",
    "One scenario might be retraining or inferencing periodically. Another scenario, if data preparation was a very expensive step, would be to run a preprocessing pipeline on one schedule and retraining on another, slower, schedule. Azure ML Pipelines give you the flexibility to tackle either of those scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "from enum import Enum\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil import parser\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Domain Data (for our example)\n",
    "from color import Color\n",
    "\n",
    "# Fake data section\n",
    "def fake_data(storage_dir) : \n",
    "\n",
    "    def generate_fake_data(minutes, mu, sigma) :\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(minutes=minutes)\n",
    "        # Generate a random amount of data\n",
    "        amount_of_fake_data = minutes * int(mu + sigma * np.random.randn())\n",
    "        # Generate at least 1 element\n",
    "        amount_of_fake_data = 1 if amount_of_fake_data < 1 else amount_of_fake_data\n",
    "        arrival_times = np.arange(start_time, end_time, timedelta(minutes = minutes / amount_of_fake_data)).astype(datetime)\n",
    "        color_votes = list(Color.randn_color().name for _ in range(amount_of_fake_data))\n",
    "        time_and_vote = zip(arrival_times, color_votes)\n",
    "        return time_and_vote\n",
    "\n",
    "    input_data_file = 'unprocessed_data.csv'\n",
    "    input_path = os.path.join(storage_dir, input_data_file)\n",
    "    # If first time, generate a bit more data \n",
    "    minutes_back = 1 if os.path.exists(input_path) else 10 \n",
    "    data = generate_fake_data(minutes_back, 100, 50)\n",
    "    with open(input_path, mode='w+') as f : \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Example of ML task code (data preprocessing)\n",
    "def read_raw_data(storage_dir) : \n",
    "    input_data_file = 'unprocessed_data.csv'\n",
    "    input_path = os.path.join(storage_dir, input_data_file)\n",
    "    if os.path.exists(input_path) : \n",
    "        with open(input_path, mode='r') as f : \n",
    "            reader = csv.reader(f)\n",
    "            return list(reader)\n",
    "    else :\n",
    "        # If file doesn't exist, return empty list \n",
    "        return []\n",
    "\n",
    "# Please note: this is just a silly example of converting and normalizing, e.g., \"preprocessing stuff\"     \n",
    "def process_raw_data(raw_data) : \n",
    "    def convert(d) :\n",
    "        for datum in d : \n",
    "            dt = parser.parse(datum[0])\n",
    "            ts = int(dt.timestamp())\n",
    "            c = Color[datum[1]].value\n",
    "            yield (ts, c)\n",
    "    processed_data = list(convert(raw_data))\n",
    "    normalized_data = normalize(processed_data, axis = 0)\n",
    "    return normalized_data\n",
    "\n",
    "def write_processed_data(storage_dir, processed_data) : \n",
    "    output_data_file = 'processed_data.csv'\n",
    "    output_path = os.path.join(storage_dir, output_data_file)\n",
    "\n",
    "    # Note: Clobbers existing processed data -- fine in this example\n",
    "    with open(output_path, mode='w') as f : \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(processed_data)\n",
    "\n",
    "def main() : \n",
    "    storage_dir = '.'\n",
    "    # Write some fake data to 'unprocessed_data.csv' -- normally data would be written via some external process\n",
    "    fake_data(storage_dir)\n",
    "    print(\"Beginning periodic data processing...\")\n",
    "    raw_data = read_raw_data(storage_dir)\n",
    "    processed_data = process_raw_data(raw_data)\n",
    "    write_processed_data(storage_dir, processed_data)\n",
    "    print(f\"Wrote {len(processed_data)} records\")\n",
    "    print(\"...Periodic data processing ended.\")\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file we just wrote:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning periodic data processing...\n",
      "Wrote 31 records\n",
      "...Periodic data processing ended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run preprocessing.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a source directory for our pipeline and move the script files to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"pipeline-scheduling-src\")\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "os.rename(\"color.py\", f\"{script_folder}/color.py\")\n",
    "os.rename(\"preprocessing.py\", f\"{script_folder}/preprocessing.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the preprocessing\n",
    "\n",
    "The **preprocessing.py** script reads unprocessed raw data and \"prepares it\" for ML. In this contrived situation, the steps are:\n",
    "\n",
    "* Read the raw data\n",
    "* Transform the human-readable record times into UNIX timestamp values \n",
    "* Transform the human-readable color \"vote\" into a numeric value\n",
    "* Normalize both the timestamps and votes \n",
    "* Write the processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2019-10-09 12:01:54.359895', 'Indigo'],\n",
       " ['2019-10-09 12:01:56.295379', 'Indigo'],\n",
       " ['2019-10-09 12:01:58.230863', 'Orange'],\n",
       " ['2019-10-09 12:02:00.166347', 'Orange'],\n",
       " ['2019-10-09 12:02:02.101831', 'Violet']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = read_raw_data('.')[0:5]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44721359, 0.53300179],\n",
       "       [0.44721359, 0.53300179],\n",
       "       [0.4472136 , 0.10660036],\n",
       "       [0.4472136 , 0.10660036],\n",
       "       [0.4472136 , 0.63960215]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = process_raw_data(raw_data)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_processed_data('.', processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and scheduling a pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.65'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "azureml.core.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "\n",
    "Go to your Machine Learning workspace and download **config.json** to the directory in which this notebook is executing:\n",
    "\n",
    "![Location of config.json file in Workspace](imgs/schedule-pipelines-download-config.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace \n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules\n",
    "\n",
    "Classes _not_ explained in the accompanying article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore, Experiment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes explained in the accompanying article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "from azureml.pipeline.core import PublishedPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_compute() :\n",
    "    compute_target = ws.compute_targets[\"cpu-compute\"]\n",
    "\n",
    "    compute_config = RunConfiguration()\n",
    "    compute_config.target = \"amlcompute\"\n",
    "    compute_config.amlcompute.vm_size = \"STANDARD_D1_V2\"\n",
    "    dependencies = CondaDependencies()\n",
    "    dependencies.add_pip_package(\"scikit-learn\")\n",
    "    compute_config.environment.python.conda_dependencies = dependencies\n",
    "    return (compute_target, compute_config)\n",
    "\n",
    "(compute_target, compute_config) = config_compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_step = PythonScriptStep(\n",
    "    script_name=\"preprocessing.py\",\n",
    "    arguments=[],\n",
    "    inputs=[],\n",
    "    outputs=[],\n",
    "    compute_target=compute_target,\n",
    "    runconfig = compute_config,\n",
    "    source_directory=\"./pipeline-scheduling-src/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "steps = [ preprocessing_step ]\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"PipelineScheduling\"\n",
    "experiment = Experiment(ws, experiment_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step preprocessing.py [b4b904d9][6258a008-b9bc-4c9f-879c-bb878e1b1c6e], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun b4a4d30a-ac8e-4de6-871e-f59dfa057b73\n",
      "Link to Azure Portal: https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/experiments/PipelineScheduling/runs/b4a4d30a-ac8e-4de6-871e-f59dfa057b73\n",
      "PipelineRunId: b4a4d30a-ac8e-4de6-871e-f59dfa057b73\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/experiments/PipelineScheduling/runs/b4a4d30a-ac8e-4de6-871e-f59dfa057b73\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: a7390e37-de02-4aa7-afa1-a3e78222b7f9\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/experiments/PipelineScheduling/runs/a7390e37-de02-4aa7-afa1-a3e78222b7f9\n",
      "StepRun( preprocessing.py ) Status: NotStarted\n",
      "StepRun( preprocessing.py ) Status: Running\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = experiment.submit(pipeline)\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish and schedule a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\"My published pipeline\",f\"Published on: {str(datetime.now())}\", \"0.0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Runs every few minutes, so you might want to slow that down for experimentation\n",
    "recurrence = ScheduleRecurrence(frequency=\"Minute\", interval=3)\n",
    "schedule = Schedule.create(ws, name=\"MySchedule\", pipeline_id=published_pipeline.id,\n",
    "                          experiment_name=experiment_name, recurrence=recurrence)\n",
    "schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"To retrieve the pipeline later, use it's `id`: {published_pipeline.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can get the schedules running in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Schedule.list(ws)\n",
    "\n",
    "if len(ss) == 0 :\n",
    "    print(\"There are currently no schedules in the workspace\")\n",
    "\n",
    "for s in ss : \n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't work if pipeline is scheduled!\n",
    "def disable_by_pipeline_id(ws, pipeline_id) : \n",
    "    p = PublishedPipeline.get(ws, id=pipeline_id)\n",
    "    p.disable()\n",
    "    return p\n",
    "    \n",
    "def disable_by_schedule_id(ws, schedule_id) : \n",
    "    s = next(s for s in Schedule.list(ws) if s.id == schedule_id)\n",
    "    s.disable()\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_id = ss[0].id\n",
    "disable_by_schedule_id(ws,schedule_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Schedule.list(ws)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
